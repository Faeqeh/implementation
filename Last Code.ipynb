{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16f6850-2dd7-43c4-a600-6a0f6f8f5f15",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779bc156-04d9-449d-8f19-c2856c4def8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from collections import Counter\n",
    "from scipy.stats import  ks_2samp, chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# تنظیم بذر تصادفی برای تکرارپذیری\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# تنظیم زمینه اجرایی محلی\n",
    "tff.backends.native.set_local_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d246e04-aec6-4a91-8693-ef6fa34d0854",
   "metadata": {},
   "source": [
    "### Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6987f8a1-152d-4002-a8ee-cd772b6324a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تابع ساخت مدل MLP\n",
    "def create_mnist_mlp_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))  # ورودی به شکل مسطح شده (28x28 = 784)\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))  # لایه خروجی با 10 کلاس (softmax)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # کامپایل کردن مدل\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4062329-af4d-4e7f-ac24-3d06b83fa354",
   "metadata": {},
   "source": [
    "### Load and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4565aca-8960-4e75-be06-fee6f7efd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# لود کردن داده‌های MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# نرمال‌سازی داده‌ها\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# مسطح کردن تصاویر\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# کدگذاری لیبل‌ها\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# تقسیم داده‌ها بین 10 کلاینت\n",
    "num_clients = 10\n",
    "client_data = np.array_split(x_train, num_clients)\n",
    "client_labels = np.array_split(y_train, num_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed859481-34a4-42c2-8527-a7f0fc08f674",
   "metadata": {},
   "source": [
    "### Bug Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8711f8c-428b-4b53-83ac-58ad1d57a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# لیستی از کلاینت‌هایی که باید دوبار نرمال‌سازی شوند\n",
    "clients_to_double_normalize = [2]  # کلاینت‌های 3 (با اندیس صفر شروع می‌شود)\n",
    "\n",
    "# دوبار نرمال‌سازی کلاینت‌های مشخص‌شده\n",
    "for client_index in clients_to_double_normalize:\n",
    "    client_data[client_index] = client_data[client_index] / 255.0\n",
    "\n",
    "# پوشه‌ای برای ذخیره پارامترهای کلاینت‌ها ایجاد می‌کنیم\n",
    "if not os.path.exists('client_params'):\n",
    "    os.makedirs('client_params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2523be-3749-4df3-bb41-b3470a3b5cac",
   "metadata": {},
   "source": [
    "### Models training & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "459da808-8791-4fa9-8768-2b7b2257b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for client 1\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6048 - accuracy: 0.8125\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.2605 - accuracy: 0.9193\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.9473\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1305 - accuracy: 0.9588\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1093 - accuracy: 0.9640\n",
      "Training completed for all clients.\n",
      "Training model for client 2\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6404 - accuracy: 0.7980\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2641 - accuracy: 0.9178\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1889 - accuracy: 0.9415\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1457 - accuracy: 0.9523\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1018 - accuracy: 0.9663\n",
      "Training completed for all clients.\n",
      "Training model for client 3\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 1.8081 - accuracy: 0.4060\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.9120 - accuracy: 0.6892\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6867 - accuracy: 0.7838\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5686 - accuracy: 0.8253\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5026 - accuracy: 0.8478\n",
      "Training completed for all clients.\n",
      "Training model for client 4\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6125 - accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2588 - accuracy: 0.9270\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1273 - accuracy: 0.9598\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1012 - accuracy: 0.9683\n",
      "Training completed for all clients.\n",
      "Training model for client 5\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6369 - accuracy: 0.8030\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.2670 - accuracy: 0.9193\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1918 - accuracy: 0.9410\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.1324 - accuracy: 0.9568\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1101 - accuracy: 0.9640\n",
      "Training completed for all clients.\n",
      "Training model for client 6\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.7938\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2666 - accuracy: 0.9183\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1872 - accuracy: 0.9415\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1287 - accuracy: 0.9580\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1066 - accuracy: 0.9650\n",
      "Training completed for all clients.\n",
      "Training model for client 7\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6523 - accuracy: 0.7983\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.2820 - accuracy: 0.9160\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2003 - accuracy: 0.9368\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1388 - accuracy: 0.9550\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1047 - accuracy: 0.9670\n",
      "Training completed for all clients.\n",
      "Training model for client 8\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6406 - accuracy: 0.7932\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.2859 - accuracy: 0.9110\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1951 - accuracy: 0.9378\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1416 - accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1120 - accuracy: 0.9672\n",
      "Training completed for all clients.\n",
      "Training model for client 9\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6508 - accuracy: 0.7995\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2869 - accuracy: 0.9110\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1990 - accuracy: 0.9360\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1451 - accuracy: 0.9543\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1116 - accuracy: 0.9630\n",
      "Training completed for all clients.\n",
      "Training model for client 10\n",
      "Weights at index 0 are identical.\n",
      "Weights at index 1 are identical.\n",
      "Weights at index 2 are identical.\n",
      "Weights at index 3 are identical.\n",
      "Weights at index 4 are identical.\n",
      "Weights at index 5 are identical.\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5558 - accuracy: 0.8270\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2244 - accuracy: 0.9335\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1501 - accuracy: 0.9523\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1040 - accuracy: 0.9672\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.0990 - accuracy: 0.9682\n",
      "Training completed for all clients.\n"
     ]
    }
   ],
   "source": [
    "# آموزش مدل‌ها برای هر کلاینت و ذخیره پارامترها\n",
    "client_models = [] #لیست برای ذخیره مدل‌های هر کلاینت\n",
    "\n",
    "base_model = create_mnist_mlp_model()  # مدل پایه\n",
    "\n",
    "#base_model.save_weights('base_model_weights.h5') # ذخیره وزن‌های مدل پایه\n",
    "\n",
    "for i in range(num_clients):\n",
    "    print(f\"Training model for client {i+1}\")    \n",
    "    model=create_mnist_mlp_model()\n",
    "    model.set_weights(base_model.get_weights())\n",
    "    \n",
    "    # بررسی یکسان بودن وزن‌ها قبل از آموزش\n",
    "    m1 = model.get_weights()\n",
    "    b1 = base_model.get_weights()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # کامپایل کردن مدل\n",
    "    for index, (base_w, clone_w) in enumerate(zip(m1, b1)):\n",
    "        if not np.array_equal(base_w, clone_w):\n",
    "            print(f\"Weights at index {index} are different.\")\n",
    "        else:\n",
    "            print(f\"Weights at index {index} are identical.\")\n",
    "    model.fit(client_data[i], client_labels[i], epochs=5, batch_size=32, verbose=1)\n",
    "    #model.save_weights(f'client_params/client_{i+1}_weights.h5') # ذخیره وزن‌های هر کلاینت\n",
    "    #print(\"**********\",model.predict(x_test[:100].argmax(axis=1)))\n",
    "    client_models.append(model)  # افزودن مدل به لیست\n",
    "    print(\"Training completed for all clients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c8110-a535-4905-88f2-53db5aef46fc",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b64986f1-6a6d-4ce6-b081-853d680d50e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Matrix for Delta Class:\n",
      "[[   0  554 1743  526  523  524  511  522  582  502]\n",
      " [ 554    0 1693  545  539  578  596  576  550  571]\n",
      " [1743 1693    0 1684 1676 1741 1745 1628 1753 1727]\n",
      " [ 526  545 1684    0  525  501  496  525  575  499]\n",
      " [ 523  539 1676  525    0  531  564  504  577  501]\n",
      " [ 524  578 1741  501  531    0  527  524  636  496]\n",
      " [ 511  596 1745  496  564  527    0  526  665  509]\n",
      " [ 522  576 1628  525  504  524  526    0  633  542]\n",
      " [ 582  550 1753  575  577  636  665  633    0  608]\n",
      " [ 502  571 1727  499  501  496  509  542  608    0]]\n",
      "\n",
      "Execution time for delta_class: 7.0223 seconds\n"
     ]
    }
   ],
   "source": [
    "def delta_class(models, x_test):\n",
    "    num_models = len(models)\n",
    "    argmax_preds = [model.predict(x_test).argmax(axis=1) for model in models]   # پیش‌بینی‌ها برای هر مدل\n",
    "    diffs_matrix = np.zeros((num_models, num_models), dtype=int)    # ماتریس مربعی برای ذخیره تفاوت‌ها\n",
    "    for i in range(num_models):       # پر کردن ماتریس با تفاوت پیش‌بینی‌ها\n",
    "        for j in range(i+1, num_models):\n",
    "            diffs = np.sum(argmax_preds[i] != argmax_preds[j])  # تعداد تفاوت‌های پیش‌بینی بین مدل i و مدل j\n",
    "            diffs_matrix[i, j] = diffs\n",
    "            diffs_matrix[j, i] = diffs  # ماتریس متقارن است\n",
    "    return diffs_matrix\n",
    "\n",
    "# اندازه‌گیری زمان\n",
    "start_time = time.time()\n",
    "diff_class = delta_class(client_models, x_test)\n",
    "print(\"Difference Matrix for Delta Class:\")\n",
    "print(diff_class)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution time for delta_class: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868a773-58cd-477e-a7e4-714f6501c957",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86b65fb0-aa33-4176-b505-2ea19e19c353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Delta Score:\n",
      "[[   0. 1450. 2310. 1348. 1394. 1330. 1363. 1396. 1460. 1353.]\n",
      " [1450.    0. 2228. 1398. 1391. 1439. 1457. 1476. 1439. 1432.]\n",
      " [2310. 2228.    0. 2174. 2200. 2190. 2215. 2128. 2322. 2240.]\n",
      " [1348. 1398. 2174.    0. 1360. 1277. 1295. 1357. 1454. 1340.]\n",
      " [1394. 1391. 2200. 1360.    0. 1319. 1352. 1332. 1488. 1329.]\n",
      " [1330. 1439. 2190. 1277. 1319.    0. 1329. 1377. 1518. 1357.]\n",
      " [1363. 1457. 2215. 1295. 1352. 1329.    0. 1330. 1548. 1334.]\n",
      " [1396. 1476. 2128. 1357. 1332. 1377. 1330.    0. 1560. 1381.]\n",
      " [1460. 1439. 2322. 1454. 1488. 1518. 1548. 1560.    0. 1551.]\n",
      " [1353. 1432. 2240. 1340. 1329. 1357. 1334. 1381. 1551.    0.]]\n",
      "\n",
      "Execution time for delta_score: 0.0000 seconds\n"
     ]
    }
   ],
   "source": [
    "def delta_score(models, x_test, threshold):\n",
    "    num_models = len(models)\n",
    "    diffs_matrix = np.zeros((num_models, num_models))\n",
    "\n",
    "    # پیش‌بینی خروجی‌های هر مدل\n",
    "    predictions = [model.predict(x_test) for model in models]\n",
    "    \n",
    "    # محاسبه‌ی argmax برای هر مدل\n",
    "    argmax_preds = [np.argmax(pred, axis=1) for pred in predictions]\n",
    "\n",
    "    # مقایسه مدل‌ها دو به دو\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            # مقایسه‌ی argmax ها\n",
    "            argmax_diff = argmax_preds[i] != argmax_preds[j]\n",
    "            diff_count = np.sum(argmax_diff)  # شمارش اختلاف در argmax\n",
    "            \n",
    "            # مقایسه‌ی احتمالات اگر argmax یکسان باشد\n",
    "            same_argmax_indices = np.where(argmax_preds[i] == argmax_preds[j])[0]\n",
    "            \n",
    "            for idx in same_argmax_indices:\n",
    "                # مقایسه‌ی احتمالات در همان کلاس‌های argmax\n",
    "                prob_i = predictions[i][idx][argmax_preds[i][idx]]\n",
    "                prob_j = predictions[j][idx][argmax_preds[j][idx]]\n",
    "                \n",
    "                # محاسبه اختلاف بین پیش‌بینی‌ها\n",
    "                prob_diff = abs(prob_i - prob_j)\n",
    "                \n",
    "                # بررسی اختلاف با آستانه threshold\n",
    "                if prob_diff >= threshold:\n",
    "                    diff_count += 1  # شمارش اختلاف در پیش‌بینی‌ها\n",
    "\n",
    "            # ذخیره اختلافات در هر دو موقعیت (i, j) و (j, i) برای متقارن بودن\n",
    "            diffs_matrix[i, j] = diff_count\n",
    "            diffs_matrix[j, i] = diff_count\n",
    "\n",
    "    return diffs_matrix\n",
    "\n",
    "\n",
    "# اجرای تابع با تعیین آستانه threshold\n",
    "diff_score = delta_score(client_models, x_test, threshold=0.1)\n",
    "print(\"Distance Matrix for Delta Score:\")\n",
    "print(diff_score)\n",
    "\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution time for delta_score: {execution_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d4da0-0228-4dd5-a914-a448216d7772",
   "metadata": {},
   "source": [
    "### KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dda1adf-1401-47d2-9067-bdf49f862091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for KS:\n",
      "[[0.     0.0636 0.8096 0.0335 0.0474 0.0822 0.0569 0.0338 0.0154 0.056 ]\n",
      " [0.0636 0.     0.7943 0.0484 0.0298 0.0307 0.0298 0.0578 0.0702 0.0159]\n",
      " [0.8096 0.7943 0.     0.7993 0.8006 0.79   0.7977 0.799  0.8048 0.8083]\n",
      " [0.0335 0.0484 0.7993 0.     0.0218 0.0677 0.0263 0.013  0.0421 0.0401]\n",
      " [0.0474 0.0298 0.8006 0.0218 0.     0.0492 0.0133 0.0309 0.0562 0.0223]\n",
      " [0.0822 0.0307 0.79   0.0677 0.0492 0.     0.0477 0.0764 0.0887 0.0316]\n",
      " [0.0569 0.0298 0.7977 0.0263 0.0133 0.0477 0.     0.0348 0.0662 0.0235]\n",
      " [0.0338 0.0578 0.799  0.013  0.0309 0.0764 0.0348 0.     0.0425 0.0502]\n",
      " [0.0154 0.0702 0.8048 0.0421 0.0562 0.0887 0.0662 0.0425 0.     0.0646]\n",
      " [0.056  0.0159 0.8083 0.0401 0.0223 0.0316 0.0235 0.0502 0.0646 0.    ]]\n",
      "\n",
      "Execution time for delta_class: 0.0000 seconds\n"
     ]
    }
   ],
   "source": [
    "def ks(models, x_test):\n",
    "    num_samples = x_test.shape[0]\n",
    "    num_models = len(models)\n",
    "\n",
    "    # مرحله 1: پیش‌بینی کلاس‌ها برای داده‌های تست توسط هر مدل\n",
    "    argmax_preds = np.array([model.predict(x_test).argmax(axis=1) for model in client_models])\n",
    "\n",
    "    # مرحله 2: یافتن کلاس پرتکرار برای هر نمونه\n",
    "    most_frequent_classes = [Counter(argmax_preds[:, i]).most_common(1)[0][0] for i in range(num_samples)]\n",
    "\n",
    "    # مرحله 3: استخراج احتمال کلاس پرتکرار از تمامی مدل‌ها برای هر نمونه\n",
    "    all_probabilities = np.zeros((num_samples, num_clients))\n",
    "    for i, model in enumerate(client_models):\n",
    "        predictions = model.predict(x_test)  # احتمالات کلاس‌های مختلف برای هر نمونه\n",
    "        for j, sample in enumerate(x_test):\n",
    "            most_frequent_class = most_frequent_classes[j]\n",
    "            all_probabilities[j, i] = predictions[j, most_frequent_class]  # احتمال کلاس پرتکرار\n",
    "    # مرحله 4: انجام تست KS بین مدل‌های کلاینت و ایجاد ماتریس KS\n",
    "    ks_distance_matrix = np.zeros((num_clients, num_clients))\n",
    "    for i in range(num_clients):\n",
    "        for j in range(i + 1, num_clients):\n",
    "            # تست KS برای مقایسه احتمالات دو مدل کلاینت\n",
    "            ks_statistic, _ = ks_2samp(all_probabilities[:, i], all_probabilities[:, j])\n",
    "            ks_distance_matrix[i, j] = ks_statistic\n",
    "            ks_distance_matrix[j, i] = ks_statistic  # ماتریس متقارن\n",
    "\n",
    "    return ks_distance_matrix\n",
    "\n",
    "# اجرای تابع با تعیین تعداد ارقام اعشار\n",
    "matrix_ks = ks(client_models, x_test)\n",
    "print(\"Distance Matrix for KS:\")\n",
    "print(matrix_ks)\n",
    "\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution time for delta_class: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be14f48-75e7-4874-9c73-7a91c69af338",
   "metadata": {},
   "source": [
    "### Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "625c0aa8-a02a-4887-80fc-1a2d6718ff07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Chi square:\n",
      "[[    0.         79333.01195652 62103.99227715 79755.88003874\n",
      "  79818.98928157 79774.76958452 80079.77541876 79888.34058736\n",
      "  78766.21570532 80191.84790918]\n",
      " [79333.01195652     0.         62473.95067528 79515.33467231\n",
      "  79576.35733202 78886.45720699 78708.75179731 79053.9194527\n",
      "  79380.90792853 78996.16413276]\n",
      " [62103.99227715 62473.95067528     0.         63043.04652187\n",
      "  62921.7477454  62530.39733589 62316.1127854  63625.78250606\n",
      "  61903.58473286 62438.85796303]\n",
      " [79755.88003874 79515.33467231 63043.04652187     0.\n",
      "  79791.01971917 80234.08191857 80391.9478384  79865.16029808\n",
      "  78897.47065496 80244.46360743]\n",
      " [79818.98928157 79576.35733202 62921.7477454  79791.01971917\n",
      "      0.         79643.9748238  79104.76777233 80265.22401841\n",
      "  78866.81466973 80229.86145314]\n",
      " [79774.76958452 78886.45720699 62530.39733589 80234.08191857\n",
      "  79643.9748238      0.         79753.08197036 79882.84787126\n",
      "  77831.36021879 80268.94856771]\n",
      " [80079.77541876 78708.75179731 62316.1127854  80391.9478384\n",
      "  79104.76777233 79753.08197036     0.         79858.00294376\n",
      "  77401.21074997 80086.94447577]\n",
      " [79888.34058736 79053.9194527  63625.78250606 79865.16029808\n",
      "  80265.22401841 79882.84787126 79858.00294376     0.\n",
      "  77997.7744273  79549.36775126]\n",
      " [78766.21570532 79380.90792853 61903.58473286 78897.47065496\n",
      "  78866.81466973 77831.36021879 77401.21074997 77997.7744273\n",
      "      0.         78317.87430129]\n",
      " [80191.84790918 78996.16413276 62438.85796303 80244.46360743\n",
      "  80229.86145314 80268.94856771 80086.94447577 79549.36775126\n",
      "  78317.87430129     0.        ]]\n",
      "\n",
      "Execution time for delta_class: 0.0000 seconds\n"
     ]
    }
   ],
   "source": [
    "def chi_square(models, x_test):\n",
    "    num_models = len(models)\n",
    "    num_samples = x_test.shape[0]\n",
    "    n_classes = 10  # تعداد کلاس ها\n",
    "\n",
    "    # ساخت ماتریس متقارن برای نتایج Chi-Square\n",
    "    chi2_matrix = np.zeros((num_models, num_models))\n",
    "    all_probabilities = np.zeros((num_samples, num_models))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        predictions = model.predict(x_test)  # احتمالات کلاس‌های مختلف برای هر نمونه\n",
    "        for j, sample in enumerate(x_test):\n",
    "            all_probabilities[j, i] = predictions[j].argmax()\n",
    "\n",
    "    # مرحله: ایجاد جدول‌های متقاطع و انجام تست Chi-Square\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            # ساخت جدول متقاطع\n",
    "            contingency_table = pd.crosstab(all_probabilities[:, i], all_probabilities[:, j])\n",
    "            chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "            chi2_matrix[i, j] = chi2_stat\n",
    "            chi2_matrix[j, i] = chi2_stat  # ماتریس متقارن\n",
    "\n",
    "    return chi2_matrix\n",
    "\n",
    "# اجرای تابع با تعیین تعداد ارقام اعشار\n",
    "matrix_chi2 = chi_square(client_models, x_test)\n",
    "print(\"Distance Matrix for Chi square:\")\n",
    "print(matrix_chi2)\n",
    "\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution time for delta_class: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a9d7c-bc15-4ec1-9672-2dc568365e48",
   "metadata": {},
   "source": [
    "### The problematic client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4a15c9-e116-42ae-a2df-8b1353324f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problemmatic Clients for Delta class [2 3 4 8]:\n",
      "Problemmatic Clients for Delta Score [2 3 4 8]:\n",
      "Problemmatic Clients for KS []:\n",
      "Problemmatic Clients for X2 [1 2 3 4 8 9]:\n"
     ]
    }
   ],
   "source": [
    "def meancal(matrix):\n",
    "    temp = 0\n",
    "    x = matrix.shape[0]    \n",
    "    arrmean = []\n",
    "    \n",
    "    for i in range(0,x):\n",
    "        #print(matrix[i].mean())\n",
    "        temp = ((matrix[i].mean())*10)/9\n",
    "        arrmean.append(temp)\n",
    "    return arrmean\n",
    "\n",
    "def iqrfunc(nparray, multiplier = 1.5):\n",
    "    data = np.array(nparray)\n",
    "    q1 = np.percentile(data,25)\n",
    "    q3 = np.percentile(data,75)\n",
    "    iqr = q3 -q1\n",
    "    lower_bound = q1-(multiplier*1.5)\n",
    "    upper_bound = q3+(multiplier*1.5)\n",
    "    outliers = np.where((data<lower_bound) | (data>upper_bound))[0]\n",
    "    return outliers\n",
    "    \n",
    "diff_class = delta_class(client_models, x_test)\n",
    "diff_score = delta_score(client_models, x_test,1)\n",
    "diff_ks = ks(client_models, x_test)\n",
    "diff_chi2 = chi_square(client_models, x_test)\n",
    "\n",
    "temp_c = meancal(diff_class)\n",
    "temp_s = meancal(diff_score)\n",
    "temp_ks = meancal(diff_ks)\n",
    "temp_chi2 = meancal(diff_chi2)\n",
    "\n",
    "print(f\"Problemmatic Clients for Delta class {iqrfunc(temp_c)}:\")                       \n",
    "print(f\"Problemmatic Clients for Delta Score {iqrfunc(temp_s)}:\")                                            \n",
    "print(f\"Problemmatic Clients for KS {iqrfunc(temp_ks)}:\")                       \n",
    "print(f\"Problemmatic Clients for X2 {iqrfunc(temp_chi2)}:\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb92da3a-1329-4f71-8629-27a7b76a8b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problemmatic Clients for Delta class [2 3 4 8]:\n",
      "Problemmatic Clients for Delta Score [2 3 4 8]:\n",
      "Problemmatic Clients for KS []:\n",
      "Problemmatic Clients for X2 [1 2 3 4 8 9]:\n",
      "\n",
      "Problemmatic Clients for Delta class [2 3 4 8]:\n",
      "Precision: 1.00, Recall: 0.67, F1 Score: 0.80, Accuracy: 0.80\n",
      "\n",
      "\n",
      "Problemmatic Clients for Delta Score [2 3 4 8]:\n",
      "Precision: 1.00, Recall: 0.67, F1 Score: 0.80, Accuracy: 0.80\n",
      "\n",
      "\n",
      "Problemmatic Clients for KS []:\n",
      "Precision: 0.00, Recall: 0.00, F1 Score: 0.00, Accuracy: 0.40\n",
      "\n",
      "\n",
      "Problemmatic Clients for X2 [1 2 3 4 8 9]:\n",
      "Precision: 1.00, Recall: 1.00, F1 Score: 1.00, Accuracy: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# فرض کنید این لیست کلاینت‌های باگ‌دار واقعی است\n",
    "# ابتدا از خروجی تحلیل‌ها برای شناسایی کلاینت‌های باگ‌دار استفاده می‌کنیم\n",
    "true_problematic_clients = []\n",
    "\n",
    "# برای هر نوع تحلیل\n",
    "for title, diff in zip([\"Delta class\", \"Delta Score\", \"KS\", \"X2\"], \n",
    "                       [temp_c, temp_s, temp_ks, temp_chi2]):\n",
    "    \n",
    "    # تبدیل لیست به آرایه NumPy\n",
    "    diff_array = np.array(diff)  \n",
    "    \n",
    "    # ایندکس کلاینت‌های باگ‌دار\n",
    "    problematic_clients = iqrfunc(meancal(diff_array))\n",
    "    print(f\"Problemmatic Clients for {title} {problematic_clients}:\")\n",
    "    \n",
    "    # به‌روزرسانی لیست کلاینت‌های باگ‌دار واقعی\n",
    "    true_problematic_clients.extend(problematic_clients.tolist())\n",
    "\n",
    "# تبدیل به آرایه numpy و حذف تکراری‌ها\n",
    "true_problematic_clients = np.unique(np.array(true_problematic_clients))\n",
    "\n",
    "# توابع برای محاسبه معیارها\n",
    "def precision(predicted, actual):\n",
    "    tp = len(np.intersect1d(predicted, actual))  # True Positives\n",
    "    fp = len(np.setdiff1d(predicted, actual))     # False Positives\n",
    "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "def recall(predicted, actual):\n",
    "    tp = len(np.intersect1d(predicted, actual))  # True Positives\n",
    "    fn = len(np.setdiff1d(actual, predicted))     # False Negatives\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "def f1_score(predicted, actual):\n",
    "    p = precision(predicted, actual)\n",
    "    r = recall(predicted, actual)\n",
    "    return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "def accuracy(predicted, actual, total_clients):\n",
    "    tp = len(np.intersect1d(predicted, actual))  # True Positives\n",
    "    tn = total_clients - len(actual) - len(predicted) + len(np.intersect1d(predicted, actual))  # True Negatives\n",
    "    return (tp + tn) / total_clients\n",
    "\n",
    "# محاسبه معیارها برای هر خروجی\n",
    "for title, diff in zip([\"Delta class\", \"Delta Score\", \"KS\", \"X2\"], \n",
    "                       [temp_c, temp_s, temp_ks, temp_chi2]):\n",
    "    \n",
    "    # تبدیل لیست به آرایه NumPy\n",
    "    diff_array = np.array(diff)\n",
    "    \n",
    "    # ایندکس کلاینت‌های باگ‌دار\n",
    "    problematic_clients = iqrfunc(meancal(diff_array))\n",
    "    print(f\"\\nProblemmatic Clients for {title} {problematic_clients}:\")\n",
    "    \n",
    "    # محاسبه معیارها\n",
    "    p = precision(problematic_clients, true_problematic_clients)\n",
    "    r = recall(problematic_clients, true_problematic_clients)\n",
    "    f1 = f1_score(problematic_clients, true_problematic_clients)\n",
    "    acc = accuracy(problematic_clients, true_problematic_clients, len(client_models))\n",
    "\n",
    "    # نمایش نتایج\n",
    "    print(f\"Precision: {p:.2f}, Recall: {r:.2f}, F1 Score: {f1:.2f}, Accuracy: {acc:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bc94d-4eea-4186-b443-27119fa25686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evn8",
   "language": "python",
   "name": "evn8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
