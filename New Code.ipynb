{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58dd6d59-1c2b-4367-94a6-ad69185382b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import tensorflow_federated as tff\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# تنظیم بذر تصادفی برای تکرارپذیری\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# تنظیم زمینه اجرایی محلی\n",
    "tff.backends.native.set_local_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a351e88-b150-4a95-8450-93893de131bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# بارگذاری داده‌ها\n",
    "(x_train_m, y_train_m), (x_test_m, y_test_m) = mnist.load_data()\n",
    "\n",
    "# نرمال‌سازی داده‌ها\n",
    "x_train_m = x_train_m.astype('float32') / 255.0\n",
    "x_test_m = x_test_m.astype('float32') / 255.0\n",
    "\n",
    "# اضافه کردن ابعاد کانال (برای MLP نیازی به این کار نیست، اما برای سازگاری با ورودی‌های مختلف)\n",
    "x_train_m = x_train_m.reshape((x_train_m.shape[0], -1))  # به شکل (batch_size, 784) تبدیل می‌شود\n",
    "x_test_m = x_test_m.reshape((x_test_m.shape[0], -1))    # به شکل (batch_size, 784) تبدیل می‌شود\n",
    "\n",
    "# کدگذاری برچسب‌ها\n",
    "y_train_m = tf.keras.utils.to_categorical(y_train_m, 10)\n",
    "y_test_m = tf.keras.utils.to_categorical(y_test_m, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2439e4e4-3ee4-4efb-a696-156103b098d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_mlp_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))     # ورودی به شکل مسطح شده (28x28 = 784)\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))     # لایه خروجی با 10 کلاس (softmax)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])     # کامپایل کردن مدل\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011a7b20-586b-4b80-9773-b57a1463ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4821 - accuracy: 0.8506\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2120 - accuracy: 0.9363\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1501 - accuracy: 0.9532\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1112 - accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0921 - accuracy: 0.9698\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4812 - accuracy: 0.8497\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2184 - accuracy: 0.9336\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1530 - accuracy: 0.9532\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1213 - accuracy: 0.9624\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0969 - accuracy: 0.9682\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4914 - accuracy: 0.8482\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2154 - accuracy: 0.9324\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1534 - accuracy: 0.9513\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1252 - accuracy: 0.9612\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0923 - accuracy: 0.9706\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4722 - accuracy: 0.8524\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2181 - accuracy: 0.9351\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1545 - accuracy: 0.9523\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1227 - accuracy: 0.9596\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1002 - accuracy: 0.9689\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4805 - accuracy: 0.8487\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2136 - accuracy: 0.9325\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1562 - accuracy: 0.9499\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1233 - accuracy: 0.9615\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0929 - accuracy: 0.9699\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3330 - accuracy: 0.5553\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6002 - accuracy: 0.8126\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4548 - accuracy: 0.8622\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3928 - accuracy: 0.8825\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.3500 - accuracy: 0.8933\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4661 - accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2065 - accuracy: 0.9375\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1517 - accuracy: 0.9541\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1263 - accuracy: 0.9608\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0950 - accuracy: 0.9704\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4901 - accuracy: 0.8467\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2192 - accuracy: 0.9367\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1577 - accuracy: 0.9528\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1225 - accuracy: 0.9632\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1014 - accuracy: 0.9671\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4801 - accuracy: 0.8503\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2122 - accuracy: 0.9355\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1537 - accuracy: 0.9532\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1270 - accuracy: 0.9589\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0978 - accuracy: 0.9696\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4869 - accuracy: 0.8457\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2186 - accuracy: 0.9323\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1558 - accuracy: 0.9518\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1262 - accuracy: 0.9588\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0941 - accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "def split_data(x, y, num_splits):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    split_indices = np.array_split(indices, num_splits)\n",
    "    split_data = [(x[indices], y[indices]) for indices in split_indices]  \n",
    "    return split_data\n",
    "    \n",
    "# تقسیم داده‌ها به کلاینت‌ها\n",
    "num_models = 5\n",
    "client_data_m = split_data(x_train_m, y_train_m, num_models)\n",
    "\n",
    "accuracy_no_bug = []  # دقت برای حالت بدون نرمال‌سازی دوباره\n",
    "accuracy_with_bug = []  # دقت برای حالت با نرمال‌سازی دوباره برای کلاینت 3\n",
    "client_models_m = []  # لیست برای ذخیره مدل‌های هر کلاینت\n",
    "\n",
    "# حالت بدون نرمال‌سازی دوباره\n",
    "for i in range(len(client_data_m)):\n",
    "    model_data_m = client_data_m[i]\n",
    "    model_mnist = create_mnist_mlp_model()\n",
    "    \n",
    "    # آموزش مدل\n",
    "    model_mnist.fit(model_data_m[0], model_data_m[1], epochs=5, batch_size=32, verbose=1)\n",
    "    client_models_m.append(model_mnist)\n",
    "    \n",
    "    # ارزیابی دقت مدل بر روی داده‌های تست\n",
    "    loss, accuracy = model_mnist.evaluate(x_test_m, y_test_m, verbose=0)\n",
    "    accuracy_no_bug.append(accuracy)  # ذخیره دقت برای حالت بدون نرمال‌سازی دوباره\n",
    "\n",
    "# حالا، برای آموزش با نرمال‌سازی دوباره برای کلاینت 3\n",
    "client_models_m = []  # لیست برای ذخیره مدل‌های هر کلاینت (دوباره خالی می‌شود)\n",
    "for i in range(len(client_data_m)):\n",
    "    model_data_m = client_data_m[i]\n",
    "    model_mnist = create_mnist_mlp_model()\n",
    "    \n",
    "    # اگر کلاینت شماره 3 باشد، نرمال‌سازی دوباره انجام می‌دهیم\n",
    "    if i==0: \n",
    "        model_data_m = (model_data_m[0] / 255.0, model_data_m[1])\n",
    "    \n",
    "    # آموزش مدل\n",
    "    model_mnist.fit(model_data_m[0], model_data_m[1], epochs=5, batch_size=32, verbose=1)\n",
    "    client_models_m.append(model_mnist)\n",
    "    \n",
    "    # ارزیابی دقت مدل بر روی داده‌های تست\n",
    "    loss, accuracy = model_mnist.evaluate(x_test_m, y_test_m, verbose=0)\n",
    "    accuracy_with_bug.append(accuracy)  # ذخیره دقت برای حالت با نرمال‌سازی دوباره"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b62de10-5151-4c16-b670-0071695528d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of client 1 without bug: 96.01%\n",
      "Accuracy of client 2 without bug: 96.21%\n",
      "Accuracy of client 3 without bug: 96.22%\n",
      "Accuracy of client 4 without bug: 95.37%\n",
      "Accuracy of client 5 without bug: 96.03%\n",
      "\n",
      "Accuracy of client 1 with bug: 84.98%\n",
      "Accuracy of client 2 with bug: 96.18%\n",
      "Accuracy of client 3 with bug: 96.08%\n",
      "Accuracy of client 4 with bug: 95.86%\n",
      "Accuracy of client 5 with bug: 96.12%\n"
     ]
    }
   ],
   "source": [
    "for i, acc in enumerate(accuracy_no_bug):\n",
    "    print(f\"Accuracy of client {i+1} without bug: {acc * 100:.2f}%\")\n",
    "print()    \n",
    "for i, acc in enumerate(accuracy_with_bug):\n",
    "    print(f\"Accuracy of client {i+1} with bug: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51195ab3-f3f4-4f9a-8183-d8a9d5138057",
   "metadata": {},
   "source": [
    "### many Samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5193c411-78e5-4159-8185-564186c4a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels for 20 Samples:\n",
      "[6 2 3 7 2 2 3 4 7 6 6 9 2 0 9 6 8 0 6 5]\n",
      "\n",
      "Predictions by Model 1:\n",
      "[6 2 3 7 2 2 3 4 7 6 8 8 2 0 9 6 2 0 6 5]\n",
      "Probability\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Predictions by Model 2:\n",
      "[6 2 3 7 7 2 3 4 7 6 6 9 2 0 9 6 2 0 6 5]\n",
      "Probability\n",
      "[0.9998536  0.999785   0.99990964 0.9874592  0.5141855  1.\n",
      " 0.9998678  0.999997   0.9999999  0.99993026 0.9996505  0.6748664\n",
      " 0.999998   0.930005   0.99998593 0.9999826  0.93072927 0.99926406\n",
      " 0.99998474 0.99998593]\n",
      "\n",
      "Predictions by Model 3:\n",
      "[6 2 3 7 2 2 3 4 7 6 6 9 2 0 9 6 2 0 6 5]\n",
      "Probability\n",
      "[0.9992865  0.9987741  0.9999862  0.9882366  0.9829228  1.\n",
      " 0.99999976 0.9999306  0.9999267  0.9272349  0.7155002  0.8817752\n",
      " 0.99999356 0.96667975 0.9997546  0.9744537  0.8992149  0.99997544\n",
      " 0.99962366 0.9999703 ]\n",
      "\n",
      "Predictions by Model 4:\n",
      "[6 2 3 7 2 2 3 4 7 6 6 9 2 0 9 6 2 0 6 5]\n",
      "Probability\n",
      "[0.9999994  0.9912287  0.9999949  0.99976903 0.6938817  1.\n",
      " 0.9999486  0.999997   1.         0.9990759  0.99395704 0.9713948\n",
      " 0.99999464 0.98012185 0.9999691  0.9999552  0.886494   0.9999496\n",
      " 0.9999428  0.9999609 ]\n",
      "\n",
      "Predictions by Model 5:\n",
      "[6 2 3 7 2 2 3 4 7 6 6 9 2 0 9 6 2 0 6 5]\n",
      "Probability\n",
      "[0.9999825  0.9997968  0.999491   0.99913824 0.99567187 1.\n",
      " 0.99989057 0.9999999  1.         0.9987878  0.9845852  0.96105194\n",
      " 0.99999964 0.65600455 0.99998736 0.9999794  0.98303    0.9999993\n",
      " 0.99997675 0.9999969 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# تنظیم دانه تصادفی\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# نرمال‌سازی داده‌ها\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# انتخاب نمونه‌ها\n",
    "num_samples = 20\n",
    "sample_indices = np.random.choice(len(x_test), size=num_samples, replace=False)\n",
    "x_sample = x_test[sample_indices].reshape(-1, 28 * 28)  # Flatten the images\n",
    "y_sample = y_test[sample_indices]\n",
    "\n",
    "# پیش‌بینی برای 20 نمونه توسط هر مدل\n",
    "preds = []\n",
    "probs = []\n",
    "\n",
    "for model in client_models_m:\n",
    "    pred_prob = model.predict(x_sample, verbose=0 )  # پیش‌بینی احتمال‌ها\n",
    "    pred_class = np.argmax(pred_prob, axis=1)  # کلاس با بیشترین احتمال\n",
    "    preds.append(pred_class)\n",
    "    probs.append(pred_prob[np.arange(num_samples), pred_class])  # احتمال کلاس پیش‌بینی‌شده\n",
    "\n",
    "# نمایش 20 نمونه و پیش‌بینی هر مدل برای آن‌ها\n",
    "print(\"True Labels for 20 Samples:\")\n",
    "print(y_sample)  # نمایش برچسب واقعی نمونه‌ها\n",
    "\n",
    "for i, (pred, prob) in enumerate(zip(preds, probs)):\n",
    "    print(f\"\\nPredictions by Model {i + 1}:\")\n",
    "    print(pred)  # نمایش پیش‌بینی هر مدل برای نمونه‌ها\n",
    "    print(\"Probability\")\n",
    "    print(prob)  # نمایش احتمال پیش‌بینی‌های صحیح\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc8b5f0-59b8-43d7-a76c-7f2374033011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Matrix for Delta Class:\n",
      "[[0 3 2 2 2]\n",
      " [3 0 1 1 1]\n",
      " [2 1 0 0 0]\n",
      " [2 1 0 0 0]\n",
      " [2 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def delta_class(models, x_test):\n",
    "    num_models = len(models)\n",
    "    preds = [model.predict(x_test).argmax(axis=1) for model in models]   # پیش‌بینی‌ها برای هر مدل\n",
    "    diffs_matrix = np.zeros((num_models, num_models), dtype=int)    # ماتریس مربعی برای ذخیره تفاوت‌ها\n",
    "    for i in range(num_models):       # پر کردن ماتریس با تفاوت پیش‌بینی‌ها\n",
    "        for j in range(i+1, num_models):\n",
    "            diffs = np.sum(preds[i] != preds[j])  # تعداد تفاوت‌های پیش‌بینی بین مدل i و مدل j\n",
    "            diffs_matrix[i, j] = diffs\n",
    "            diffs_matrix[j, i] = diffs  # ماتریس متقارن است\n",
    "    return diffs_matrix\n",
    "\n",
    "diff_class = delta_class(client_models_m, x_sample)\n",
    "print(\"Difference Matrix for Delta Class:\")\n",
    "print(diff_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7412d22-8fa8-40ce-b66d-67a5dbd31f0b",
   "metadata": {},
   "source": [
    "### اختلاف در احتمال واقعی با در نظر گرفتن کل مقدار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6488eeb-1a3d-4e55-9a39-2e34435fdf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Delta Score:\n",
      "[[ 0. 19. 19. 18. 18.]\n",
      " [19.  0. 19. 18. 19.]\n",
      " [19. 19.  0. 19. 19.]\n",
      " [18. 18. 19.  0. 18.]\n",
      " [18. 19. 19. 18.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_score_av(models, x_test):\n",
    "    preds = [model.predict(x_test) for model in models]\n",
    "    num_models = len(models)\n",
    "    delta_matrix = np.zeros((num_models, num_models))\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        argmax_i = np.argmax(preds[i], axis=1)\n",
    "        for j in range(num_models):\n",
    "            if i != j:\n",
    "                argmax_j = np.argmax(preds[j], axis=1)\n",
    "\n",
    "                # محاسبه تعداد اختلافات در argmax\n",
    "                argmax_diff = np.sum(argmax_i != argmax_j)\n",
    "                prob_diff = 0\n",
    "                for k in range(len(argmax_i)):\n",
    "                    if argmax_i[k] == argmax_j[k]:\n",
    "                        # احتمال کلاس پیش‌بینی‌شده\n",
    "                        prob_i = preds[i][k][argmax_i[k]]\n",
    "                        prob_j = preds[j][k][argmax_j[k]]\n",
    "                        \n",
    "                        # بررسی اختلاف در احتمال‌ها\n",
    "                        if prob_i != prob_j:\n",
    "                            prob_diff += 1\n",
    "                \n",
    "                delta_matrix[i, j] = argmax_diff + prob_diff\n",
    "    \n",
    "    return delta_matrix\n",
    "    \n",
    "# اجرای تابع با مدل‌ها و نمونه‌ها\n",
    "diff_score = delta_score_av(client_models_m, x_sample)\n",
    "print(\"Distance Matrix for Delta Score:\")\n",
    "print(diff_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f7922-2516-41dc-bdf4-e8812fc54a24",
   "metadata": {},
   "source": [
    "### اختلاف در مقدار صحیح بدون در نظر گرفتن رقم اعشار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673ac45b-7feb-4bf6-8bd8-48ef50d6f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Delta Score:\n",
      "[[ 0. 19. 19. 18. 18.]\n",
      " [19.  0.  1.  2.  2.]\n",
      " [19.  1.  0.  1.  1.]\n",
      " [18.  2.  1.  0.  0.]\n",
      " [18.  2.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_score_nd(models, x_test):\n",
    "    # پیش‌بینی‌ها و احتمال‌ها برای هر مدل\n",
    "    preds = [model.predict(x_test) for model in models]\n",
    "    # ماتریس برای ذخیره اختلافات\n",
    "    num_models = len(models)\n",
    "    delta_matrix = np.zeros((num_models, num_models))\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        argmax_i = np.argmax(preds[i], axis=1)\n",
    "        for j in range(num_models):\n",
    "            if i != j:\n",
    "                argmax_j = np.argmax(preds[j], axis=1)\n",
    "\n",
    "                # محاسبه تعداد اختلافات در argmax\n",
    "                argmax_diff = np.sum(argmax_i != argmax_j)\n",
    "\n",
    "                # محاسبه تعداد اختلافات در احتمال‌ها\n",
    "                prob_diff = 0\n",
    "                for k in range(len(argmax_i)):\n",
    "                    # فقط بررسی می‌کنیم اگر argmax برابر باشد\n",
    "                    if argmax_i[k] == argmax_j[k]:\n",
    "                        # گرفتن احتمال‌ها\n",
    "                        prob_i = preds[i][k]\n",
    "                        prob_j = preds[j][k]\n",
    "                        \n",
    "                        # بررسی اختلاف بدون گرد کردن و محاسبه تعداد تفاوت‌ها\n",
    "                        if int(prob_i[np.argmax(prob_i)]) != int(prob_j[np.argmax(prob_j)]):\n",
    "                            prob_diff += 1\n",
    "                \n",
    "                # ذخیره اختلافات در ماتریس\n",
    "                delta_matrix[i, j] = argmax_diff + prob_diff\n",
    "    \n",
    "    return delta_matrix\n",
    "\n",
    "# اجرای تابع با مدل‌ها و نمونه‌ها\n",
    "diff_score = delta_score_nd(client_models_m, x_sample)\n",
    "print(\"Distance Matrix for Delta Score:\")\n",
    "print(diff_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46b45d-462c-4003-95d3-8ac44f4ab70d",
   "metadata": {},
   "source": [
    "### اختلاف با تغییر جایگاه اعشار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59be4381-88df-47f4-8664-08ded881996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Delta Score:\n",
      "[[ 0. 19. 19. 18. 18.]\n",
      " [19.  0.  4.  4.  4.]\n",
      " [19.  4.  0.  4.  5.]\n",
      " [18.  4.  4.  0.  3.]\n",
      " [18.  4.  5.  3.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_score_d1(models, x_test, decimal_places):\n",
    "    num_models = len(models)\n",
    "    deltas = np.zeros((num_models, num_models))\n",
    "\n",
    "    # پیش‌بینی خروجی‌های هر مدل\n",
    "    predictions = [model.predict(x_test) for model in models]\n",
    "    \n",
    "    # محاسبه‌ی argmax برای هر مدل\n",
    "    argmax_preds = [np.argmax(pred, axis=1) for pred in predictions]\n",
    "\n",
    "    # مقایسه مدل‌ها دو به دو\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            # مقایسه‌ی argmax ها\n",
    "            argmax_diff = argmax_preds[i] != argmax_preds[j]\n",
    "            diff_count = np.sum(argmax_diff)  # شمارش اختلاف در argmax\n",
    "            \n",
    "            # مقایسه‌ی احتمالات اگر argmax یکسان باشد\n",
    "            same_argmax_indices = np.where(argmax_preds[i] == argmax_preds[j])[0]\n",
    "            \n",
    "            for idx in same_argmax_indices:\n",
    "                # مقایسه‌ی احتمالات در همان کلاس‌های argmax\n",
    "                prob_i = predictions[i][idx][argmax_preds[i][idx]]\n",
    "                prob_j = predictions[j][idx][argmax_preds[j][idx]]\n",
    "                \n",
    "                # استخراج رشته‌ی ارقام اعشار تا تعداد مشخص‌شده\n",
    "                prob_i_str = str(prob_i)[:decimal_places + 2]  # 2 برای \"0.\"\n",
    "                prob_j_str = str(prob_j)[:decimal_places + 2]\n",
    "\n",
    "                # بررسی اختلاف در ارقام اعشار\n",
    "                if prob_i_str != prob_j_str:\n",
    "                    diff_count += 1  # شمارش اختلاف در احتمال\n",
    "\n",
    "            # ذخیره اختلافات در هر دو موقعیت (i, j) و (j, i) برای متقارن بودن\n",
    "            deltas[i, j] = diff_count\n",
    "            deltas[j, i] = diff_count\n",
    "\n",
    "    return deltas\n",
    "\n",
    "# اجرای تابع با تعیین تعداد ارقام اعشار\n",
    "diff_score = delta_score_d1(client_models_m, x_sample, decimal_places=1)\n",
    "print(\"Distance Matrix for Delta Score:\")\n",
    "print(diff_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb7a9d20-02db-42cc-855b-7af2564c171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Delta Score:\n",
      "[[ 0. 19. 19. 18. 18.]\n",
      " [19.  0.  7.  6.  7.]\n",
      " [19.  7.  0.  9.  9.]\n",
      " [18.  6.  9.  0.  5.]\n",
      " [18.  7.  9.  5.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_score_d2(models, x_test, decimal_places):\n",
    "    num_models = len(models)\n",
    "    deltas = np.zeros((num_models, num_models))\n",
    "\n",
    "    # پیش‌بینی خروجی‌های هر مدل\n",
    "    predictions = [model.predict(x_test) for model in models]\n",
    "    \n",
    "    # محاسبه‌ی argmax برای هر مدل\n",
    "    argmax_preds = [np.argmax(pred, axis=1) for pred in predictions]\n",
    "\n",
    "    # مقایسه مدل‌ها دو به دو\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            # مقایسه‌ی argmax ها\n",
    "            argmax_diff = argmax_preds[i] != argmax_preds[j]\n",
    "            diff_count = np.sum(argmax_diff)  # شمارش اختلاف در argmax\n",
    "            \n",
    "            # مقایسه‌ی احتمالات اگر argmax یکسان باشد\n",
    "            same_argmax_indices = np.where(argmax_preds[i] == argmax_preds[j])[0]\n",
    "            \n",
    "            for idx in same_argmax_indices:\n",
    "                # مقایسه‌ی احتمالات در همان کلاس‌های argmax\n",
    "                prob_i = predictions[i][idx][argmax_preds[i][idx]]\n",
    "                prob_j = predictions[j][idx][argmax_preds[j][idx]]\n",
    "                \n",
    "                # استخراج رشته‌ی ارقام اعشار تا تعداد مشخص‌شده\n",
    "                prob_i_str = str(prob_i)[:decimal_places + 2]  # 2 برای \"0.\"\n",
    "                prob_j_str = str(prob_j)[:decimal_places + 2]\n",
    "\n",
    "                # بررسی اختلاف در ارقام اعشار\n",
    "                if prob_i_str != prob_j_str:\n",
    "                    diff_count += 1  # شمارش اختلاف در احتمال\n",
    "\n",
    "            # ذخیره اختلافات در هر دو موقعیت (i, j) و (j, i) برای متقارن بودن\n",
    "            deltas[i, j] = diff_count\n",
    "            deltas[j, i] = diff_count\n",
    "\n",
    "    return deltas\n",
    "\n",
    "# اجرای تابع با تعیین تعداد ارقام اعشار\n",
    "diff_score = delta_score_d2(client_models_m, x_sample, decimal_places=2)\n",
    "print(\"Distance Matrix for Delta Score:\")\n",
    "print(diff_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13188c52-92b8-4f08-8d4c-852e2add7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for KS:\n",
      "[[ 0. 19. 19. 18. 18.]\n",
      " [19.  0. 19. 18. 19.]\n",
      " [19. 19.  0. 19. 19.]\n",
      " [18. 18. 19.  0. 18.]\n",
      " [18. 19. 19. 18.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def p_ks(models, x_test):\n",
    "    n_models = len(models)\n",
    "    n_samples = x_test.shape[0]\n",
    "    \n",
    "    # پیش‌بینی مدل‌ها برای x_test\n",
    "    model_predictions = [model.predict(x_test) for model in models]\n",
    "    \n",
    "    # ساخت ماتریس متقارن برای نتایج KS\n",
    "    ks_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    # بررسی تک تک نمونه‌ها\n",
    "    for i in range(n_samples):\n",
    "        # پیدا کردن برچسب اکثریت برای این نمونه\n",
    "        majority_labels = [np.argmax(pred[i]) for pred in model_predictions]\n",
    "        majority_label = np.bincount(majority_labels).argmax()\n",
    "\n",
    "        # گرفتن احتمال هر مدل برای برچسب اکثریت\n",
    "        majority_probs = [pred[i][majority_label] for pred in model_predictions]\n",
    "\n",
    "        # محاسبه تست KS بین مدل‌ها\n",
    "        for m1 in range(n_models):\n",
    "            for m2 in range(m1 + 1, n_models):\n",
    "                ks_stat, _ = ks_2samp([majority_probs[m1]], [majority_probs[m2]])\n",
    "                ks_matrix[m1, m2] += ks_stat\n",
    "                ks_matrix[m2, m1] = ks_matrix[m1, m2]  # ماتریس متقارن\n",
    "\n",
    "    # تقسیم بر تعداد نمونه‌ها برای نرمال‌سازی\n",
    "    # ks_matrix /= n_samples\n",
    "    return ks_matrix\n",
    "\n",
    "diff_ks = p_ks(client_models_m, x_sample)\n",
    "print(\"Distance Matrix for KS:\")\n",
    "print(diff_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5673ae9b-3ae2-46d1-8a66-4409b31320e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for x2:\n",
      "[[0.0e+00 1.0e+08 1.0e+08 1.0e+08 1.0e+08]\n",
      " [1.0e+08 0.0e+00 3.5e-02 3.5e-02 3.5e-02]\n",
      " [1.0e+08 3.5e-02 0.0e+00 0.0e+00 0.0e+00]\n",
      " [1.0e+08 3.5e-02 0.0e+00 0.0e+00 0.0e+00]\n",
      " [1.0e+08 3.5e-02 0.0e+00 0.0e+00 0.0e+00]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "def p_x2(models, x_test):\n",
    "    # تعداد مدل‌ها\n",
    "    num_models = len(models)\n",
    "\n",
    "    # پیش‌بینی برچسب‌ها توسط مدل‌ها\n",
    "    predictions = np.array([model.predict(x_test) for model in models])  # shape: (num_models, num_samples, num_classes)\n",
    "\n",
    "    # اطمینان از اینکه پیش‌بینی‌ها به صورت دسته‌ای هستند\n",
    "    if len(predictions.shape) != 3:\n",
    "        raise ValueError(\"Predictions must be a 3D array with shape (num_models, num_samples, num_classes).\")\n",
    "\n",
    "    # برچسب اکثریت برای هر نمونه\n",
    "    majority_labels = np.argmax(predictions, axis=2)  # shape: (num_models, num_samples)\n",
    "\n",
    "    # محاسبه احتمال هر برچسب\n",
    "    probabilities = np.array([[np.mean(majority_labels[i] == j) for j in range(np.max(majority_labels) + 1)]\n",
    "                              for i in range(num_models)])  # shape: (num_models, num_classes)\n",
    "\n",
    "    # اضافه کردن مقدار کوچک برای جلوگیری از تقسیم بر صفر\n",
    "    probabilities += 1e-10  # جلوگیری از صفر در احتمال‌ها\n",
    "\n",
    "    # محاسبه ماتریس Chi-square\n",
    "    x2_distance_matrix = np.zeros((num_models, num_models))\n",
    "\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            # استفاده از تست Chi-square برای محاسبه فاصله\n",
    "            stat, p = chisquare(probabilities[i], f_exp=probabilities[j])\n",
    "            x2_distance_matrix[i, j] = stat\n",
    "            x2_distance_matrix[j, i] = stat  # ماتریس متقارن\n",
    "\n",
    "    return x2_distance_matrix\n",
    "    \n",
    "# Example usage\n",
    "diff_x2 = p_x2(client_models_m, x_sample)\n",
    "print(\"Distance Matrix for x2:\")\n",
    "print(diff_x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b122f52-7f2c-4b5b-92d3-8c188d50b77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b4231-aa36-4324-9f82-dfe272fd816f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a956dcd-cbaa-463a-a147-711bfe6fb1e0",
   "metadata": {},
   "source": [
    "### problam client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dca32c6-da33-462f-aa8a-96e32aa5c307",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delta_score_d2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m diff_class \u001b[38;5;241m=\u001b[39m delta_class(client_models_m, x_test_m)\n\u001b[0;32m     23\u001b[0m diff_score1 \u001b[38;5;241m=\u001b[39m delta_score_d1(client_models_m, x_test_m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m diff_score2 \u001b[38;5;241m=\u001b[39m \u001b[43mdelta_score_d2\u001b[49m(client_models_m, x_test_m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     25\u001b[0m diff_score_nd \u001b[38;5;241m=\u001b[39m delta_score_nd(client_models_m, x_test_m)\n\u001b[0;32m     26\u001b[0m diff_score_av \u001b[38;5;241m=\u001b[39m delta_score_av(client_models_m, x_test_m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'delta_score_d2' is not defined"
     ]
    }
   ],
   "source": [
    "def meancal(matrix):\n",
    "    temp = 0\n",
    "    x = matrix.shape[0]    \n",
    "    arrmean = []\n",
    "    \n",
    "    for i in range(0,x):\n",
    "        #print(matrix[i].mean())\n",
    "        temp = ((matrix[i].mean())*10)/9\n",
    "        arrmean.append(temp)\n",
    "    return arrmean\n",
    "\n",
    "def iqrfunc(nparray, multiplier = 1.5):\n",
    "    data = np.array(nparray)\n",
    "    q1 = np.percentile(data,25)\n",
    "    q3 = np.percentile(data,75)\n",
    "    iqr = q3 -q1\n",
    "    lower_bound = q1-(multiplier*1.5)\n",
    "    upper_bound = q3+(multiplier*1.5)\n",
    "    outliers = np.where((data<lower_bound) | (data>upper_bound))[0]\n",
    "    return outliers\n",
    "    \n",
    "diff_class = delta_class(client_models_m, x_test_m)\n",
    "diff_score1 = delta_score_d1(client_models_m, x_test_m,1)\n",
    "diff_score2 = delta_score_d2(client_models_m, x_test_m,2)\n",
    "diff_score_nd = delta_score_nd(client_models_m, x_test_m)\n",
    "diff_score_av = delta_score_av(client_models_m, x_test_m)\n",
    "diff_ks = p_ks(client_models_m, x_test_m)\n",
    "diff_x2 = p_x2(client_models_m, x_test_m)\n",
    "# diff_x2 = delta_x2(client_models_m, x_test_m)\n",
    "\n",
    "temp_c = meancal(diff_class)\n",
    "temp_s1 = meancal(diff_score1)\n",
    "temp_s2 = meancal(diff_score2)\n",
    "temp_snd = meancal(diff_score_nd)\n",
    "temp_sav = meancal(diff_score_av)\n",
    "temp_ks = meancal(diff_ks)\n",
    "temp_x2 = meancal(diff_x2)\n",
    "# temp_x2 = meancal(diff_score)\n",
    "print(f\"Problemmatic Clients for Delta class {iqrfunc(temp_c)}:\")                       \n",
    "print(f\"Problemmatic Clients for Delta Score Decimal1 {iqrfunc(temp_s1)}:\")                       \n",
    "print(f\"Problemmatic Clients for Delta Score Decimal2 {iqrfunc(temp_s2)}:\")                       \n",
    "print(f\"Problemmatic Clients for Delta Score No Decimal {iqrfunc(temp_snd)}:\")                       \n",
    "print(f\"Problemmatic Clients for Delta Score Actual value {iqrfunc(temp_sav)}:\")                       \n",
    "print(f\"Problemmatic Clients for KS {iqrfunc(temp_ks)}:\")                       \n",
    "print(f\"Problemmatic Clients for X2 {iqrfunc(temp_x2)}:\")                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e54756-d355-4230-8f0b-26b2d75fe309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8774096e-5e4c-4cd2-bfd0-baecfe08e273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e072e25e-c5c1-4378-ae79-efbf14050a1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ahanin code's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc10b0f-c6d2-40a5-abff-e3779f8302bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix:\n",
      "[[0. 3. 2. 2. 2.]\n",
      " [3. 0. 1. 1. 1.]\n",
      " [2. 1. 0. 0. 0.]\n",
      " [2. 1. 0. 0. 0.]\n",
      " [2. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_class(model1, model2, x_test):\n",
    "    # Make predictions on the test data\n",
    "    predictions1 = np.argmax(model1.predict(x_test), axis=1)\n",
    "    predictions2 = np.argmax(model2.predict(x_test), axis=1)\n",
    "    \n",
    "    # Count the number of differing predictions\n",
    "    count = np.sum(predictions1 != predictions2)\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Initialize the distance matrix\n",
    "num_clients = len(client_models_m)\n",
    "distance_matrix = np.zeros((num_clients, num_clients))\n",
    "\n",
    "# Calculate the delta class for each pair of models\n",
    "for i in range(num_clients):\n",
    "    for j in range(i + 1, num_clients):\n",
    "        distance_matrix[i, j] = delta_class(client_models_m[i], client_models_m[j],x_sample)\n",
    "        distance_matrix[j, i] = distance_matrix[i, j]  # Symmetric matrix\n",
    "\n",
    "# Print the distance matrix\n",
    "print(\"Distance Matrix:\")\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9bc46b-684a-4280-a473-d6fb13e662fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta Score Matrix:\n",
      "[[0. 5. 4. 4. 3.]\n",
      " [5. 0. 5. 3. 4.]\n",
      " [4. 5. 0. 4. 5.]\n",
      " [4. 3. 4. 0. 3.]\n",
      " [3. 4. 5. 3. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_score(model1, model2, x_test, threshold=0.1):\n",
    "    # Make predictions on the test data\n",
    "    predictions1 = model1.predict(x_test)\n",
    "    predictions2 = model2.predict(x_test)\n",
    "    \n",
    "    # Get the predicted labels and their probabilities\n",
    "    labels1 = np.argmax(predictions1, axis=1)\n",
    "    labels2 = np.argmax(predictions2, axis=1)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(labels1)):\n",
    "        # Check if the predicted labels are different\n",
    "        if labels1[i] != labels2[i]:\n",
    "            count += 1\n",
    "        else:\n",
    "            # If labels are the same, compare the probabilities rounded to 1 decimal place\n",
    "            prob1 = round(predictions1[i][labels1[i]], 1)\n",
    "            prob2 = round(predictions2[i][labels2[i]], 1)\n",
    "            if abs(prob1 - prob2) > threshold:  # Compare probabilities\n",
    "                count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Initialize the distance matrix\n",
    "num_clients = len(client_models_m)\n",
    "delta_score_matrix = np.zeros((num_clients, num_clients))\n",
    "\n",
    "# Calculate the delta score for each pair of models\n",
    "for i in range(num_clients):\n",
    "    for j in range(i + 1, num_clients):\n",
    "        delta_score_matrix[i, j] = delta_score(client_models_m[i], client_models_m[j], x_sample)\n",
    "        delta_score_matrix[j, i] = delta_score_matrix[i, j]  # Symmetric matrix\n",
    "\n",
    "# Print the delta score matrix\n",
    "print(\"Delta Score Matrix:\")\n",
    "print(delta_score_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6e3534-334c-49ed-b4e7-0fc258ead808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Test Statistic Matrix:\n",
      "[[0.      0.89507 0.89606 0.89517 0.89534]\n",
      " [0.89507 0.      0.0793  0.07589 0.08482]\n",
      " [0.89606 0.0793  0.      0.09489 0.10277]\n",
      " [0.89517 0.07589 0.09489 0.      0.06699]\n",
      " [0.89534 0.08482 0.10277 0.06699 0.     ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def ks_test(model1, model2, x_test):\n",
    "    # Make predictions on the test data\n",
    "    predictions1 = model1.predict(x_test)\n",
    "    predictions2 = model2.predict(x_test)\n",
    "    \n",
    "    # Initialize a list to store KS statistics for each class\n",
    "    ks_stats = []\n",
    "    \n",
    "    # Perform KS test for each class and store the KS statistic\n",
    "    for i in range(predictions1.shape[1]):\n",
    "        ks_stat, _ = ks_2samp(predictions1[:, i], predictions2[:, i])\n",
    "        ks_stats.append(ks_stat)\n",
    "    \n",
    "    return ks_stats\n",
    "\n",
    "# Initialize a matrix to store KS test results\n",
    "num_clients = len(client_models_m)\n",
    "ks_stat_matrix = np.zeros((num_clients, num_clients))\n",
    "\n",
    "# Calculate the KS test for each pair of models\n",
    "for i in range(num_clients):\n",
    "    for j in range(i + 1, num_clients):\n",
    "        ks_stats = ks_test(client_models_m[i], client_models_m[j], x_test_m)\n",
    "        ks_stat_matrix[i, j] = np.mean(ks_stats)\n",
    "        ks_stat_matrix[j, i] = ks_stat_matrix[i, j]  # Symmetric matrix\n",
    "\n",
    "# Print the KS test statistic matrix\n",
    "print(\"KS Test Statistic Matrix:\")\n",
    "print(ks_stat_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d674b300-c281-470d-bcda-9eb7b442b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Test Statistic Matrix:\n",
      "[[    0.         65999.36986572 66069.9587529  65416.70235105\n",
      "  66681.73215678]\n",
      " [65999.36986572     0.         81534.16052464 81571.11264982\n",
      "  82840.61392205]\n",
      " [66069.9587529  81534.16052464     0.         81773.43585289\n",
      "  82352.77255414]\n",
      " [65416.70235105 81571.11264982 81773.43585289     0.\n",
      "  82065.7629604 ]\n",
      " [66681.73215678 82840.61392205 82352.77255414 82065.7629604\n",
      "      0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(model1, model2, x_test):\n",
    "    # Make predictions on the test data\n",
    "    predictions1 = np.argmax(model1.predict(x_test), axis=1)\n",
    "    predictions2 = np.argmax(model2.predict(x_test), axis=1)\n",
    "    \n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((10, 10))\n",
    "    for i in range(len(predictions1)):\n",
    "        contingency_table[predictions1[i], predictions2[i]] += 1\n",
    "    \n",
    "    # Perform Chi-Square test\n",
    "    chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "    return chi2_stat\n",
    "\n",
    "# Initialize a matrix to store Chi-Square test results\n",
    "num_clients = len(client_models_m)\n",
    "chi2_stat_matrix = np.zeros((num_clients, num_clients))\n",
    "\n",
    "# Calculate the Chi-Square test for each pair of models\n",
    "for i in range(num_clients):\n",
    "    for j in range(i + 1, num_clients):\n",
    "        chi2_stat = chi_square_test(client_models_m[i], client_models_m[j], x_test_m)\n",
    "        chi2_stat_matrix[i, j] = chi2_stat\n",
    "        chi2_stat_matrix[j, i] = chi2_stat  # Symmetric matrix\n",
    "\n",
    "# Print the Chi-Square test statistic matrix\n",
    "print(\"Chi-Square Test Statistic Matrix:\")\n",
    "print(chi2_stat_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d29d2a-dd00-416d-b8e6-7ee4aa29022f",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evn8",
   "language": "python",
   "name": "evn8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
