{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16f6850-2dd7-43c4-a600-6a0f6f8f5f15",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779bc156-04d9-449d-8f19-c2856c4def8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOP\\anaconda3\\envs\\evn8\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.18.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from collections import Counter\n",
    "from scipy.stats import  ks_2samp, chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# تنظیم بذر تصادفی برای تکرارپذیری\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "# تنظیم زمینه اجرایی محلی\n",
    "tff.backends.native.set_local_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d246e04-aec6-4a91-8693-ef6fa34d0854",
   "metadata": {},
   "source": [
    "### Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6987f8a1-152d-4002-a8ee-cd772b6324a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تابع ساخت مدل MLP\n",
    "def create_mnist_mlp_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))  # ورودی به شکل مسطح شده (28x28 = 784)\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))  # لایه خروجی با 10 کلاس (softmax)\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # کامپایل کردن مدل\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4062329-af4d-4e7f-ac24-3d06b83fa354",
   "metadata": {},
   "source": [
    "### Load and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4565aca-8960-4e75-be06-fee6f7efd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# لود کردن داده‌های MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# نرمال‌سازی داده‌ها\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# مسطح کردن تصاویر\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# کدگذاری لیبل‌ها\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# تقسیم داده‌ها بین 10 کلاینت\n",
    "num_clients = 10\n",
    "client_data = np.array_split(x_train, num_clients)\n",
    "client_labels = np.array_split(y_train, num_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed859481-34a4-42c2-8527-a7f0fc08f674",
   "metadata": {},
   "source": [
    "### Bug Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8711f8c-428b-4b53-83ac-58ad1d57a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# لیستی از کلاینت‌هایی که باید دوبار نرمال‌سازی شوند\n",
    "clients_to_double_normalize = [0]  # کلاینت‌های 3,6 (با اندیس صفر شروع می‌شود)\n",
    "\n",
    "# دوبار نرمال‌سازی کلاینت‌های مشخص‌شده\n",
    "for client_index in clients_to_double_normalize:\n",
    "    client_data[client_index] = client_data[client_index] / 255.0\n",
    "\n",
    "# پوشه‌ای برای ذخیره پارامترهای کلاینت‌ها ایجاد می‌کنیم\n",
    "if not os.path.exists('client_params'):\n",
    "    os.makedirs('client_params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2523be-3749-4df3-bb41-b3470a3b5cac",
   "metadata": {},
   "source": [
    "### Models training & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "459da808-8791-4fa9-8768-2b7b2257b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for client 1\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 1.7547 - accuracy: 0.4307\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.8341 - accuracy: 0.7257\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6179 - accuracy: 0.8108\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.5142 - accuracy: 0.8487\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.4509 - accuracy: 0.8643\n",
      "Training model for client 2\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6452 - accuracy: 0.7978\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2675 - accuracy: 0.9180\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1824 - accuracy: 0.9413\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1370 - accuracy: 0.9568\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1088 - accuracy: 0.9643\n",
      "Training model for client 3\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6814 - accuracy: 0.7805\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2795 - accuracy: 0.9103\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1956 - accuracy: 0.9368\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1363 - accuracy: 0.9547\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9658\n",
      "Training model for client 4\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6314 - accuracy: 0.8008\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.2604 - accuracy: 0.9203\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.94 - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9423\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1280 - accuracy: 0.9597\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1029 - accuracy: 0.9670\n",
      "Training model for client 5\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6477 - accuracy: 0.7917\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2716 - accuracy: 0.9165\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1779 - accuracy: 0.9427\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1382 - accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0946 - accuracy: 0.9682\n",
      "Training model for client 6\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.6439 - accuracy: 0.7928\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.2688 - accuracy: 0.9208\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1834 - accuracy: 0.9430\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1294 - accuracy: 0.9588\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1055 - accuracy: 0.9657\n",
      "Training model for client 7\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6624 - accuracy: 0.7903\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2785 - accuracy: 0.9138\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9372\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9532\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9633\n",
      "Training model for client 8\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6570 - accuracy: 0.7907\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.2884 - accuracy: 0.9097\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1951 - accuracy: 0.9368\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1506 - accuracy: 0.9518\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9648\n",
      "Training model for client 9\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6582 - accuracy: 0.7865\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2740 - accuracy: 0.9167\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1906 - accuracy: 0.9425\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1380 - accuracy: 0.9563\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9632\n",
      "Training model for client 10\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.8225\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9295\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1455 - accuracy: 0.9528\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1113 - accuracy: 0.9655\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0834 - accuracy: 0.9733\n",
      "Training completed for all clients.\n"
     ]
    }
   ],
   "source": [
    "# آموزش مدل‌ها برای هر کلاینت و ذخیره پارامترها\n",
    "client_models = [] #لیست برای ذخیره مدل‌های هر کلاینت\n",
    "\n",
    "base_model = create_mnist_mlp_model()  # مدل پایه\n",
    "\n",
    "#base_model.save_weights('base_model_weights.h5') # ذخیره وزن‌های مدل پایه\n",
    "\n",
    "for i in range(num_clients):\n",
    "    print(f\"Training model for client {i+1}\")    \n",
    "    model=create_mnist_mlp_model()\n",
    "    model.set_weights(base_model.get_weights())\n",
    "    \n",
    "    # بررسی یکسان بودن وزن‌ها قبل از آموزش\n",
    "    # m1 = model.get_weights()\n",
    "    # b1 = base_model.get_weights()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # کامپایل کردن مدل\n",
    "    # for index, (base_w, clone_w) in enumerate(zip(m1, b1)):\n",
    "    #     if not np.array_equal(base_w, clone_w):\n",
    "    #         print(f\"Weights at index {index} are different.\")\n",
    "    #     else:\n",
    "    #         print(f\"Weights at index {index} are identical.\")\n",
    "    model.fit(client_data[i], client_labels[i], epochs=5, batch_size=32, verbose=1)\n",
    "    #model.save_weights(f'client_params/client_{i+1}_weights.h5') # ذخیره وزن‌های هر کلاینت\n",
    "    #print(\"**********\",model.predict(x_test[:100].argmax(axis=1)))\n",
    "    client_models.append(model)  # افزودن مدل به لیست\n",
    "print(\"Training completed for all clients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c8110-a535-4905-88f2-53db5aef46fc",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b64986f1-6a6d-4ce6-b081-853d680d50e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Matrix for Delta Class:\n",
      "[[   0 1993 1877 1947 1974 1851 2071 1935 1918 1960]\n",
      " [1993    0  551  558  534  519  656  641  529  595]\n",
      " [1877  551    0  492  540  444  608  521  474  530]\n",
      " [1947  558  492    0  584  543  579  572  546  561]\n",
      " [1974  534  540  584    0  548  688  637  536  552]\n",
      " [1851  519  444  543  548    0  635  507  515  552]\n",
      " [2071  656  608  579  688  635    0  634  672  636]\n",
      " [1935  641  521  572  637  507  634    0  607  548]\n",
      " [1918  529  474  546  536  515  672  607    0  514]\n",
      " [1960  595  530  561  552  552  636  548  514    0]]\n"
     ]
    }
   ],
   "source": [
    "def delta_class(models, x_test):\n",
    "    num_models = len(models)\n",
    "    argmax_preds = [model.predict(x_test).argmax(axis=1) for model in models]   # پیش‌بینی‌ها برای هر مدل\n",
    "    diffs_matrix = np.zeros((num_models, num_models), dtype=int)    # ماتریس مربعی برای ذخیره تفاوت‌ها\n",
    "    for i in range(num_models):       # پر کردن ماتریس با تفاوت پیش‌بینی‌ها\n",
    "        for j in range(i+1, num_models):\n",
    "            diffs = np.sum(argmax_preds[i] != argmax_preds[j])  # تعداد تفاوت‌های پیش‌بینی بین مدل i و مدل j\n",
    "            diffs_matrix[i, j] = diffs\n",
    "            diffs_matrix[j, i] = diffs  # ماتریس متقارن است\n",
    "    return diffs_matrix\n",
    "\n",
    "# اندازه‌گیری زمان\n",
    "start_time = time.time()\n",
    "diff_class = delta_class(client_models, x_test)\n",
    "print(\"Difference Matrix for Delta Class:\")\n",
    "print(diff_class)\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "# print(f\"\\nExecution time for delta_class: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868a773-58cd-477e-a7e4-714f6501c957",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86b65fb0-aa33-4176-b505-2ea19e19c353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Delta Score:\n",
      "[[   0. 2503. 2320. 2460. 2435. 2253. 2703. 2500. 2422. 2489.]\n",
      " [2503.    0. 1390. 1403. 1372. 1351. 1655. 1563. 1368. 1490.]\n",
      " [2320. 1390.    0. 1344. 1359. 1187. 1554. 1459. 1303. 1390.]\n",
      " [2460. 1403. 1344.    0. 1406. 1288. 1480. 1471. 1391. 1415.]\n",
      " [2435. 1372. 1359. 1406.    0. 1279. 1588. 1544. 1298. 1352.]\n",
      " [2253. 1351. 1187. 1288. 1279.    0. 1531. 1352. 1296. 1358.]\n",
      " [2703. 1655. 1554. 1480. 1588. 1531.    0. 1624. 1638. 1570.]\n",
      " [2500. 1563. 1459. 1471. 1544. 1352. 1624.    0. 1558. 1430.]\n",
      " [2422. 1368. 1303. 1391. 1298. 1296. 1638. 1558.    0. 1384.]\n",
      " [2489. 1490. 1390. 1415. 1352. 1358. 1570. 1430. 1384.    0.]]\n"
     ]
    }
   ],
   "source": [
    "def delta_score(models, x_test, threshold):\n",
    "    num_models = len(models)\n",
    "    diffs_matrix = np.zeros((num_models, num_models))\n",
    "\n",
    "    # پیش‌بینی خروجی‌های هر مدل\n",
    "    predictions = [model.predict(x_test) for model in models]\n",
    "    \n",
    "    # محاسبه‌ی argmax برای هر مدل\n",
    "    argmax_preds = [np.argmax(pred, axis=1) for pred in predictions]\n",
    "\n",
    "    # مقایسه مدل‌ها دو به دو\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            diff_count = 0  # شمارنده اختلافات\n",
    "\n",
    "            # مقایسه‌ی argmax ها\n",
    "            argmax_diff = argmax_preds[i] != argmax_preds[j]\n",
    "            diff_count += np.sum(argmax_diff)  # اضافه کردن اختلاف در argmax\n",
    "            \n",
    "            # مقایسه‌ی احتمالات برای پیش‌بینی‌های با argmax یکسان\n",
    "            same_argmax_indices = np.where(argmax_preds[i] == argmax_preds[j])[0]\n",
    "            \n",
    "            for idx in same_argmax_indices:\n",
    "                # مقایسه‌ی احتمالات در همان کلاس‌های argmax\n",
    "                prob_i = round(predictions[i][idx][argmax_preds[i][idx]], 2)\n",
    "                prob_j = round(predictions[j][idx][argmax_preds[j][idx]], 2)\n",
    "                \n",
    "                # محاسبه اختلاف بین پیش‌بینی‌ها\n",
    "                prob_diff = abs(prob_i - prob_j)\n",
    "                \n",
    "                # بررسی اختلاف با آستانه threshold\n",
    "                if prob_diff >= threshold:\n",
    "                    diff_count += 1  # شمارش اختلاف در پیش‌بینی‌ها\n",
    "\n",
    "            # ذخیره اختلافات در هر دو موقعیت (i, j) و (j, i) برای متقارن بودن\n",
    "            diffs_matrix[i, j] = diff_count\n",
    "            diffs_matrix[j, i] = diff_count\n",
    "\n",
    "    return diffs_matrix\n",
    "\n",
    "# اجرای تابع با تعیین آستانه threshold\n",
    "diff_score = delta_score(client_models, x_test, threshold=0.1)\n",
    "print(\"Distance Matrix for Delta Score:\")\n",
    "print(diff_score)\n",
    "\n",
    "# start_time = time.time()\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "# print(f\"\\nExecution time for delta_score: {execution_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d4da0-0228-4dd5-a914-a448216d7772",
   "metadata": {},
   "source": [
    "### KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0dda1adf-1401-47d2-9067-bdf49f862091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for KS:\n",
      "[[0.     0.7898 0.7769 0.7812 0.7726 0.7851 0.7921 0.7846 0.7841 0.7788]\n",
      " [0.7898 0.     0.0359 0.0487 0.0707 0.0532 0.0683 0.0324 0.0165 0.0207]\n",
      " [0.7769 0.0359 0.     0.0422 0.0995 0.0504 0.0584 0.0396 0.0364 0.027 ]\n",
      " [0.7812 0.0487 0.0422 0.     0.109  0.0756 0.0292 0.0226 0.0477 0.0503]\n",
      " [0.7726 0.0707 0.0995 0.109  0.     0.0651 0.128  0.0873 0.0656 0.0886]\n",
      " [0.7851 0.0532 0.0504 0.0756 0.0651 0.     0.094  0.0631 0.0431 0.0375]\n",
      " [0.7921 0.0683 0.0584 0.0292 0.128  0.094  0.     0.0457 0.0664 0.0671]\n",
      " [0.7846 0.0324 0.0396 0.0226 0.0873 0.0631 0.0457 0.     0.0261 0.0392]\n",
      " [0.7841 0.0165 0.0364 0.0477 0.0656 0.0431 0.0664 0.0261 0.     0.0246]\n",
      " [0.7788 0.0207 0.027  0.0503 0.0886 0.0375 0.0671 0.0392 0.0246 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "def ks(models, x_test):\n",
    "    num_samples = x_test.shape[0]\n",
    "    num_models = len(models)\n",
    "\n",
    "    # مرحله 1: پیش‌بینی کلاس‌ها برای داده‌های تست توسط هر مدل\n",
    "    argmax_preds = np.array([model.predict(x_test).argmax(axis=1) for model in client_models])\n",
    "\n",
    "    # مرحله 2: یافتن کلاس پرتکرار برای هر نمونه\n",
    "    most_frequent_classes = [Counter(argmax_preds[:, i]).most_common(1)[0][0] for i in range(num_samples)]\n",
    "\n",
    "    # مرحله 3: استخراج احتمال کلاس پرتکرار از تمامی مدل‌ها برای هر نمونه\n",
    "    all_probabilities = np.zeros((num_samples, num_clients))\n",
    "    for i, model in enumerate(client_models):\n",
    "        predictions = model.predict(x_test)  # احتمالات کلاس‌های مختلف برای هر نمونه\n",
    "        for j, sample in enumerate(x_test):\n",
    "            most_frequent_class = most_frequent_classes[j]\n",
    "            all_probabilities[j, i] = predictions[j, most_frequent_class]  # احتمال کلاس پرتکرار\n",
    "    # مرحله 4: انجام تست KS بین مدل‌های کلاینت و ایجاد ماتریس KS\n",
    "    ks_distance_matrix = np.zeros((num_clients, num_clients))\n",
    "    for i in range(num_clients):\n",
    "        for j in range(i + 1, num_clients):\n",
    "            # تست KS برای مقایسه احتمالات دو مدل کلاینت\n",
    "            ks_statistic, _ = ks_2samp(all_probabilities[:, i], all_probabilities[:, j])\n",
    "            ks_distance_matrix[i, j] = ks_statistic\n",
    "            ks_distance_matrix[j, i] = ks_statistic  # ماتریس متقارن\n",
    "\n",
    "    return ks_distance_matrix\n",
    "\n",
    "# اجرای تابع با تعیین تعداد ارقام اعشار\n",
    "matrix_ks = ks(client_models, x_test)\n",
    "print(\"Distance Matrix for KS:\")\n",
    "print(matrix_ks)\n",
    "\n",
    "# start_time = time.time()\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "# print(f\"\\nExecution time for delta_class: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be14f48-75e7-4874-9c73-7a91c69af338",
   "metadata": {},
   "source": [
    "### Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "625c0aa8-a02a-4887-80fc-1a2d6718ff07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix for Chi square:\n",
      "[[    0.         59254.46147014 60981.72176082 60273.98429588\n",
      "  59588.56213485 61156.46079432 58658.79557984 60344.67810457\n",
      "  60539.66473789 60487.85914148]\n",
      " [59254.46147014     0.         79361.84315696 79162.47486044\n",
      "  79536.89488198 79954.74428068 77608.67620493 77822.72137767\n",
      "  79714.5580719  78569.49731061]\n",
      " [60981.72176082 79361.84315696     0.         80410.25267403\n",
      "  79531.26101984 81280.48592136 78501.10363998 79962.93300736\n",
      "  80764.94613892 79748.006255  ]\n",
      " [60273.98429588 79162.47486044 80410.25267403     0.\n",
      "  78677.54376724 79474.33080307 78862.8591814  79039.91029528\n",
      "  79431.76530798 79161.25960421]\n",
      " [59588.56213485 79536.89488198 79531.26101984 78677.54376724\n",
      "      0.         79380.56117829 76975.00455101 77922.70022703\n",
      "  79540.25785321 79334.63434682]\n",
      " [61156.46079432 79954.74428068 81280.48592136 79474.33080307\n",
      "  79380.56117829     0.         77948.97989547 80250.30392468\n",
      "  80004.87347588 79392.77737483]\n",
      " [58658.79557984 77608.67620493 78501.10363998 78862.8591814\n",
      "  76975.00455101 77948.97989547     0.         77970.27198758\n",
      "  77337.74981005 77942.18502993]\n",
      " [60344.67810457 77822.72137767 79962.93300736 79039.91029528\n",
      "  77922.70022703 80250.30392468 77970.27198758     0.\n",
      "  78449.61324493 79538.82750041]\n",
      " [60539.66473789 79714.5580719  80764.94613892 79431.76530798\n",
      "  79540.25785321 80004.87347588 77337.74981005 78449.61324493\n",
      "      0.         79991.79405286]\n",
      " [60487.85914148 78569.49731061 79748.006255   79161.25960421\n",
      "  79334.63434682 79392.77737483 77942.18502993 79538.82750041\n",
      "  79991.79405286     0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def chi_square(models, x_test):\n",
    "    num_models = len(models)\n",
    "    num_samples = x_test.shape[0] # تعداد نمونه‌ها  \n",
    "    n_classes = 10  # تعداد کلاس ها\n",
    "\n",
    "    # ساخت ماتریس متقارن برای نتایج Chi-Square\n",
    "    chi2_matrix = np.zeros((num_models, num_models))\n",
    "    all_probabilities = np.zeros((num_samples, num_models))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        predictions = model.predict(x_test)  # احتمالات کلاس‌های مختلف برای هر نمونه\n",
    "        for j, sample in enumerate(x_test):\n",
    "            all_probabilities[j, i] = predictions[j].argmax()\n",
    "\n",
    "    # مرحله: ایجاد جدول‌های متقاطع و انجام تست Chi-Square\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            # ساخت جدول متقاطع\n",
    "            contingency_table = pd.crosstab(all_probabilities[:, i], all_probabilities[:, j])\n",
    "            chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "            chi2_matrix[i, j] = chi2_stat\n",
    "            chi2_matrix[j, i] = chi2_stat  # ماتریس متقارن\n",
    "\n",
    "    return chi2_matrix\n",
    "\n",
    "# اجرای تابع با تعیین تعداد ارقام اعشار\n",
    "matrix_chi2 = chi_square(client_models, x_test)\n",
    "print(\"Distance Matrix for Chi square:\")\n",
    "print(matrix_chi2)\n",
    "\n",
    "# start_time = time.time()\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "# print(f\"\\nExecution time for delta_class: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a9d7c-bc15-4ec1-9672-2dc568365e48",
   "metadata": {},
   "source": [
    "### The problematic client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa4a15c9-e116-42ae-a2df-8b1353324f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problemmatic Clients for Delta class [0 6]:\n",
      "Problemmatic Clients for Delta Score [0]:\n",
      "Problemmatic Clients for KS [0]:\n",
      "Problemmatic Clients for X2 [0 6]:\n"
     ]
    }
   ],
   "source": [
    "def meancal(matrix):\n",
    "    temp = 0\n",
    "    x = matrix.shape[0]    \n",
    "    arrmean = []\n",
    "    \n",
    "    for i in range(0,x):\n",
    "        #print(matrix[i].mean())\n",
    "        temp = (matrix[i].mean())    \n",
    "        arrmean.append(temp)\n",
    "    return arrmean\n",
    "\n",
    "def iqrfunc(nparray):\n",
    "    data = np.array(nparray)\n",
    "    q1 = np.percentile(data,25)\n",
    "    q3 = np.percentile(data,75)\n",
    "    iqr = q3 -q1\n",
    "    lower_bound = q1-(iqr*1.5)\n",
    "    upper_bound = q3+(iqr*1.5)\n",
    "    outliers = np.where((data<lower_bound) | (data>upper_bound))[0]\n",
    "    return outliers\n",
    "    \n",
    "diff_class = delta_class(client_models, x_test)\n",
    "diff_score = delta_score(client_models, x_test,0.1)\n",
    "diff_ks = ks(client_models, x_test)\n",
    "diff_chi2 = chi_square(client_models, x_test)\n",
    "\n",
    "temp_c = meancal(diff_class)\n",
    "temp_s = meancal(diff_score)\n",
    "temp_ks = meancal(diff_ks)\n",
    "temp_chi2 = meancal(diff_chi2)\n",
    "\n",
    "print(f\"Problemmatic Clients for Delta class {iqrfunc(temp_c)}:\")                       \n",
    "print(f\"Problemmatic Clients for Delta Score {iqrfunc(temp_s)}:\")                                            \n",
    "print(f\"Problemmatic Clients for KS {iqrfunc(temp_ks)}:\")                       \n",
    "print(f\"Problemmatic Clients for X2 {iqrfunc(temp_chi2)}:\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c546477-ea7c-445b-acdb-366861899630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5c1f7-0498-497f-85ff-686598e3987b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37837f89-daf9-496b-b414-38b7f485c55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "853c899c-b247-4e4c-a2ef-5e83b8d2e338",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92da3a-1329-4f71-8629-27a7b76a8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # فرض کنید این لیست کلاینت‌های باگ‌دار واقعی است\n",
    "# # ابتدا از خروجی تحلیل‌ها برای شناسایی کلاینت‌های باگ‌دار استفاده می‌کنیم\n",
    "# true_problematic_clients = []\n",
    "\n",
    "# # برای هر نوع تحلیل\n",
    "# for title, diff in zip([\"Delta class\", \"Delta Score\", \"KS\", \"X2\"], \n",
    "#                        [temp_c, temp_s, temp_ks, temp_chi2]):\n",
    "    \n",
    "#     # تبدیل لیست به آرایه NumPy\n",
    "#     diff_array = np.array(diff)  \n",
    "    \n",
    "#     # ایندکس کلاینت‌های باگ‌دار\n",
    "#     problematic_clients = iqrfunc(meancal(diff_array))\n",
    "#     print(f\"Problemmatic Clients for {title} {problematic_clients}:\")\n",
    "    \n",
    "#     # به‌روزرسانی لیست کلاینت‌های باگ‌دار واقعی\n",
    "#     true_problematic_clients.extend(problematic_clients.tolist())\n",
    "\n",
    "# # تبدیل به آرایه numpy و حذف تکراری‌ها\n",
    "# true_problematic_clients = np.unique(np.array(true_problematic_clients))\n",
    "\n",
    "# # توابع برای محاسبه معیارها\n",
    "# def precision(predicted, actual):\n",
    "#     tp = len(np.intersect1d(predicted, actual))  # True Positives\n",
    "#     fp = len(np.setdiff1d(predicted, actual))     # False Positives\n",
    "#     return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "# def recall(predicted, actual):\n",
    "#     tp = len(np.intersect1d(predicted, actual))  # True Positives\n",
    "#     fn = len(np.setdiff1d(actual, predicted))     # False Negatives\n",
    "#     return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "# def f1_score(predicted, actual):\n",
    "#     p = precision(predicted, actual)\n",
    "#     r = recall(predicted, actual)\n",
    "#     return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "# def accuracy(predicted, actual, total_clients):\n",
    "#     tp = len(np.intersect1d(predicted, actual))  # True Positives\n",
    "#     tn = total_clients - len(actual) - len(predicted) + len(np.intersect1d(predicted, actual))  # True Negatives\n",
    "#     return (tp + tn) / total_clients\n",
    "\n",
    "# # محاسبه معیارها برای هر خروجی\n",
    "# for title, diff in zip([\"Delta class\", \"Delta Score\", \"KS\", \"X2\"], \n",
    "#                        [temp_c, temp_s, temp_ks, temp_chi2]):\n",
    "    \n",
    "#     # تبدیل لیست به آرایه NumPy\n",
    "#     diff_array = np.array(diff)\n",
    "    \n",
    "#     # ایندکس کلاینت‌های باگ‌دار\n",
    "#     problematic_clients = iqrfunc(meancal(diff_array))\n",
    "#     print(f\"\\nProblemmatic Clients for {title} {problematic_clients}:\")\n",
    "    \n",
    "#     # محاسبه معیارها\n",
    "#     p = precision(problematic_clients, true_problematic_clients)\n",
    "#     r = recall(problematic_clients, true_problematic_clients)\n",
    "#     f1 = f1_score(problematic_clients, true_problematic_clients)\n",
    "#     acc = accuracy(problematic_clients, true_problematic_clients, len(client_models))\n",
    "\n",
    "#     # نمایش نتایج\n",
    "#     print(f\"Precision: {p:.2f}, Recall: {r:.2f}, F1 Score: {f1:.2f}, Accuracy: {acc:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bc94d-4eea-4186-b443-27119fa25686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # تابع محاسبه میانگین\n",
    "# def meancal(matrix):\n",
    "#     x = matrix.shape[0]    \n",
    "#     arrmean = []\n",
    "#     for i in range(x):\n",
    "#         temp = ((matrix[i].mean()) * 10) / 9\n",
    "#         arrmean.append(temp)\n",
    "#     return arrmean\n",
    "\n",
    "# # محاسبه میانگین‌ها برای ماتریس‌های مختلف\n",
    "# temp_c = meancal(diff_class)\n",
    "# temp_s = meancal(diff_score)\n",
    "# temp_ks = meancal(diff_ks)\n",
    "# temp_chi2 = meancal(diff_chi2)\n",
    "\n",
    "# # داده‌ها و برچسب‌ها برای رسم نمودار\n",
    "# data = [temp_c, temp_s, temp_ks, temp_chi2]\n",
    "# labels = ['diff_class', 'diff_score', 'diff_ks', 'diff_chi2']\n",
    "\n",
    "# # رسم نمودار box plot\n",
    "# plt.boxplot(data, labels=labels)\n",
    "# plt.title('Boxplot of Calculated Means')\n",
    "# plt.ylabel('Values')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b80a33e9-4952-48f3-85a3-c228674f30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # فرضیات: جایگزین‌های داده‌های diff_class, diff_score, diff_ks, diff_chi2\n",
    "# np.random.seed(42)  # برای بازتولید پذیری\n",
    "# diff_class = np.random.rand(5, 10)  # ماتریس تصادفی 5x10 برای نمایش\n",
    "# diff_score = np.random.rand(5, 10)  # ماتریس تصادفی 5x10\n",
    "# diff_ks = np.random.rand(5, 10)  # ماتریس تصادفی 5x10\n",
    "# diff_chi2 = np.random.rand(5, 10)  # ماتریس تصادفی 5x10\n",
    "\n",
    "# # تابع محاسبه میانگین\n",
    "# def meancal(matrix):\n",
    "#     x = matrix.shape[0]    \n",
    "#     arrmean = []\n",
    "#     for i in range(x):\n",
    "#         temp = ((matrix[i].mean()) * 10) / 9\n",
    "#         arrmean.append(temp)\n",
    "#     return arrmean\n",
    "\n",
    "# # محاسبه میانگین‌ها برای ماتریس‌های مختلف\n",
    "# temp_c = meancal(diff_class)\n",
    "# temp_s = meancal(diff_score)\n",
    "# temp_ks = meancal(diff_ks)\n",
    "# temp_chi2 = meancal(diff_chi2)\n",
    "\n",
    "# # نمودار برای diff_class\n",
    "# plt.figure()\n",
    "# plt.boxplot(temp_c)\n",
    "# plt.title('Boxplot of diff_class')\n",
    "# plt.ylabel('Values')\n",
    "# plt.show()\n",
    "\n",
    "# # نمودار برای diff_score\n",
    "# plt.figure()\n",
    "# plt.boxplot(temp_s)\n",
    "# plt.title('Boxplot of diff_score')\n",
    "# plt.ylabel('Values')\n",
    "# plt.show()\n",
    "\n",
    "# # نمودار برای diff_ks\n",
    "# plt.figure()\n",
    "# plt.boxplot(temp_ks)\n",
    "# plt.title('Boxplot of diff_ks')\n",
    "# plt.ylabel('Values')\n",
    "# plt.show()\n",
    "\n",
    "# # نمودار برای diff_chi2\n",
    "# plt.figure()\n",
    "# plt.boxplot(temp_chi2)\n",
    "# plt.title('Boxplot of diff_chi2')\n",
    "# plt.ylabel('Values')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba0301-1567-426b-b4c7-8eb01322c863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evn8",
   "language": "python",
   "name": "evn8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
